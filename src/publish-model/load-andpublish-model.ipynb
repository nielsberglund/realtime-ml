{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Publish Model\n",
    "\n",
    "In this `.ipynb` you will load up the model you created and saved in [`create-save-model.ipynb`](../ml-create-model/create-save-model.ipynb) and publish it to a Kafka topic.\n",
    "\n",
    "#### Pre-reqs\n",
    "\n",
    "In the `create-save-model.ipynb` file you installed most of the pre-reqs. For the code in this file you only need a couple of things:\n",
    "\n",
    "* `confluent-kafka`: the Python package for Kafka.\n",
    "* Kafka: well, since we are using Kafka - you need it.\n",
    "\n",
    "#### Kafka\n",
    "\n",
    "You can either run Kafka on-prem or using Confluent Cloud. Here I am running Kafka using Docker. You can find the `docker-compose.yml` file I use [here](../../docker/docker-compose.yml).\n",
    "\n",
    "When you have a running Kafka cluster, (whether Docker, on-prem, or Confluent Cloud) you need two topics:\n",
    "\n",
    "* `models`: this is where we push the model to (and we use in this file).\n",
    "* `adclicks`: this topic is where we emulate rel-time events (adclicks) is published to.\n",
    "\n",
    "To create the topics in a Docker environment:\n",
    "\n",
    "```\n",
    "docker-compose exec broker kafka-topics --create --bootstrap-server \\\n",
    "localhost:9092 --replication-factor 1 --partitions 1 --topic models\n",
    "\n",
    "docker-compose exec broker kafka-topics --create --bootstrap-server \\\n",
    "localhost:9092 --replication-factor 1 --partitions 1 --topic adclicks\n",
    "```\n",
    "\n",
    "The `\\` in the code above denotes a line continuation.\n",
    "\n",
    "We are almost ready. We need to import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import socket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model\n",
    "\n",
    "Let us load the model we saved off to [`adcklick.pkl`](../../models/adclick.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the model\n",
    "lr_model = pickle.load(open('../../models/adclick.pkl', 'rb'))\n",
    "\n",
    "# create a bytearray and decode into a string to represent the model\n",
    "modBin = pickle.dumps(lr_model).decode('latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Publish the Event\n",
    "\n",
    "Having the string representation we can create an event. The event looks like so:\n",
    "\n",
    "`{modelId: int, modelName: string, model: string}`\n",
    "\n",
    "The `model` field holds the model string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an event\n",
    "modelEvent = {\n",
    "    \"modelId\": 2,\n",
    "    \"modelName\": 'adclicks-logreg',\n",
    "    \"model\": modBin\n",
    "}\n",
    "\n",
    "modelEventString = json.dumps(modelEvent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Publisher\n",
    "\n",
    "Let us setup the publisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the Producer from the confluent_kafka library\n",
    "from confluent_kafka import Producer\n",
    "\n",
    "# create the publisher configuration\n",
    "conf = {'bootstrap.servers': 'localhost:9092',\n",
    "        'client.id': socket.gethostname()}\n",
    "\n",
    "# create the producer\n",
    "producer = Producer(conf)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publish the Event\n",
    "\n",
    "We are now in a position where we can publish the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start with setting up a callback function to handle the delivery report\n",
    "def acked(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {0}: {1}\".format(msg.value(), err.str()))\n",
    "    else:\n",
    "        print(\"Message produced: {0}\".format(msg.value()))\n",
    "\n",
    "# publish the model\n",
    "producer.produce('model', key=\"1\", value=modelEventString, callback=acked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3bc87c33ce804fde0b7e38c4a6eb6a05850fcc5ecf42cac42cfaaf92923d0e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
